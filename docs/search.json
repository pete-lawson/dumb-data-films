[
  {
    "objectID": "data-exploration.html",
    "href": "data-exploration.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\nimport duckdb\nimport re\n\nScrape page for details\n\nresponse = requests.get('https://hub.jhu.edu/2015/10/13/johns-hopkins-on-film/')\nsoup = BeautifulSoup(response.content, 'html.parser')\n\n\nprint(soup.prettify())\n\n\ntitles_raw = soup.find_all('strong')\ntitles_cleaned = []\nfor title in titles_raw:\n    title_name_element = title.find('em')\n    title_name = title_name_element.getText(strip=True)\n    title_name_element.extract()\n    title_year_raw = title.get_text(strip=True)\n    title_year = re.search(r'(?&lt;=\\()(\\d*)', title_year_raw).group(0)\n    titles_cleaned.append({'Title': title_name, 'Year': title_year})\ntitles_data = pd.DataFrame(titles_cleaned) \ntitles_data.to_csv('data/cleaned/jhu-titles.csv', index=False)\n\nThe resulting jhu-titles.csv can be shared with learners, and the code to scrape the information can be shared post-session for those that are interested."
  },
  {
    "objectID": "data-exploration.html#scrape-jhu-titles-from-blog-post",
    "href": "data-exploration.html#scrape-jhu-titles-from-blog-post",
    "title": "",
    "section": "",
    "text": "import pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\nimport duckdb\nimport re\n\nScrape page for details\n\nresponse = requests.get('https://hub.jhu.edu/2015/10/13/johns-hopkins-on-film/')\nsoup = BeautifulSoup(response.content, 'html.parser')\n\n\nprint(soup.prettify())\n\n\ntitles_raw = soup.find_all('strong')\ntitles_cleaned = []\nfor title in titles_raw:\n    title_name_element = title.find('em')\n    title_name = title_name_element.getText(strip=True)\n    title_name_element.extract()\n    title_year_raw = title.get_text(strip=True)\n    title_year = re.search(r'(?&lt;=\\()(\\d*)', title_year_raw).group(0)\n    titles_cleaned.append({'Title': title_name, 'Year': title_year})\ntitles_data = pd.DataFrame(titles_cleaned) \ntitles_data.to_csv('data/cleaned/jhu-titles.csv', index=False)\n\nThe resulting jhu-titles.csv can be shared with learners, and the code to scrape the information can be shared post-session for those that are interested."
  },
  {
    "objectID": "data-exploration.html#retrieving-the-imdb-titles-that-correspond-to-the-titles-listed-in-jhu-titles.csv",
    "href": "data-exploration.html#retrieving-the-imdb-titles-that-correspond-to-the-titles-listed-in-jhu-titles.csv",
    "title": "",
    "section": "Retrieving the IMDB titles that correspond to the titles listed in jhu-titles.csv",
    "text": "Retrieving the IMDB titles that correspond to the titles listed in jhu-titles.csv\nThis is more challenging than you might expect – there are a number of duplicate titles for some of the JHU titles, so we need to do a little data cleaning, as well as some manual data exploration.\nThe IMDB tabular data is large, so I use duckdb here to allow me to treat them as a SQL database.\n\ncon = duckdb.connect()\n\nQuery matching titles\n\n# Query for rows in IMDB title basics where the corresponding \n# title and year are present for the titles scraped from the JHU site\ntitles = con.execute(\n    \"\"\"\n    SELECT *\n    FROM read_csv_auto(\n    \"./data/title.basics.tsv\", \n    header=True,\n    nullstr=\"\\\\N\") as tb\n    JOIN titles_data as td ON tb.originalTitle = td.Title\n    WHERE tb.startYear = td.Year\n    \"\"\"\n).fetchdf()\ntitles.to_csv('data/cleaned/imdb-title-matches.csv', index=False)"
  },
  {
    "objectID": "data-exploration.html#selecting-matching-titles",
    "href": "data-exploration.html#selecting-matching-titles",
    "title": "",
    "section": "Selecting matching titles",
    "text": "Selecting matching titles\nMultiple joins with CTE’s\n\n# Query for rows in IMDB title basics where the corresponding\n# title and year are present for the titles scraped from the JHU site\ndf = con.execute(\n    \"\"\"\n    WITH tb AS(\n    SELECT *\n    FROM read_csv_auto(\n        \"./data/title.basics.tsv\", \n        header=True,\n        nullstr=\"\\\\N\"\n    ) as titles_basics\n    JOIN titles_data \n    ON titles_basics.originalTitle = titles_data.Title\n    WHERE titles_basics.startYear = titles_data.Year),\n\n    tr AS(\n        SELECT \n        tb.*,\n        tr.averageRating,\n        tr.numVotes \n    FROM tb\n    JOIN read_csv_auto(\n        \"./data/title.ratings.tsv\",\n        header=True,\n        nullstr=\"\\\\N\"\n    ) as tr\n    ON tb.tconst = tr.tconst\n    )\n    SELECT *\n    FROM tr\n    \"\"\"\n).fetchdf()\n\nData cleaning - find unique title and category\n\ndf['startYear'] = pd.to_datetime(df['startYear'], format='%Y', errors='coerce')\ndf['endYear'] = pd.to_datetime(df['endYear'], format='%Y', errors='coerce')\n# Locate first year of title, for all title and title type combinations\ndf.loc[df.groupby(['titleType', 'primaryTitle']).startYear.idxmin().dropna()]\n\n#Questions:\n#- For TV shows, do we return an average rating across all seasons/episodes?\n\n#Get rotten tomato ratings:\n\nrt_scores = pd.read_csv('./data/movie_info.csv')\ntitle_rt_scores = rt_scores[rt_scores['title'].isin(titles)]\n\nQuestions/Comments\n\nMany titles missing in Rotten Tomatoes scores.\nHow do we disambiguate House of Cards show from 1968 movie.\n\nScrape rotten tomatoes for individual titles:\n\nresponse = requests.get('https://www.rottentomatoes.com/tv/house-of-cards')\nsoup = BeautifulSoup(response.content, 'html.parser')\n\n\ncritics_score = soup.find(\"rt-text\", attrs={\"slot\": \"criticsScore\", \"role\":\"button\"}).get_text(strip=True)\n\naudience_score = soup.find(\"rt-text\", attrs={\"slot\": \"audienceScore\", \"role\":\"button\"}).get_text(strip=True)\n\nBreadcrumbs: - Turn scraper into function. - Add TV or Movie to titles, as Rotten Tomatos URLs are either m or tv depending, i.e. https://www.rottentomatoes.com/tv/house_of_cards\n\nmedium = ['m', 'm', 'tv', 'm', 'm', 'm', 'm', 'tv', 'm', 'tv', 'tv', 'm', 'm']\n\n\n# Call function\ndef url_constructor(title, medium):\n    rt_title = re.sub(r\"[^a-z0-9_]\", \"\", title.lower().replace(\" \", \"_\"))\n    return f'https://www.rottentomatoes.com/{medium}/{rt_title}'\n\n\nrt_urls = []\nfor title, med in zip(titles, medium):\n    url = url_constructor(title, med)\n    rt_urls.append(url) \n\n\ndef get_rt_ratings(url):\n    try: \n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.content, 'html.parser')\n        critics_score = soup.find(\"rt-text\", attrs={\"slot\": \"criticsScore\", \"role\":\"button\"}).get_text(strip=True)\n        audience_score = soup.find(\"rt-text\", attrs={\"slot\": \"audienceScore\", \"role\":\"button\"}).get_text(strip=True)\n        return {'critics': critics_score,'audience': audience_score}\n    except requests.exceptions.HTTPError as err:\n        return {'critics': None,'audience': None}\n\n\naudience_scores = []\ncritics_scores = []\nfor url in rt_urls:\n    scores = get_rt_ratings(url)\n    audience_scores.append(scores.get('audience'))\n    critics_scores.append(scores.get('critics'))\n\nConstruct dataframe of media and ratings\n\ndata = {\"media\": titles,\n\"audience_score\": audience_scores, \n\"critics_scores\": critics_scores}\n\ndf = pd.DataFrame(data)"
  }
]
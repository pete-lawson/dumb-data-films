---
author: Pete Lawson
format: html
---

## Scrape JHU titles from blog post

```{python}
import pandas as pd
import requests
from bs4 import BeautifulSoup
import duckdb
import re
```

Scrape page for details

```{python}
response = requests.get('https://hub.jhu.edu/2015/10/13/johns-hopkins-on-film/')
soup = BeautifulSoup(response.content, 'html.parser')
```


```{python}
print(soup.prettify())
```


```{python}
titles_raw = soup.find_all('strong')
titles_cleaned = []
for title in titles_raw:
    title_name_element = title.find('em')
    title_name = title_name_element.getText(strip=True)
    title_name_element.extract()
    title_year_raw = title.get_text(strip=True)
    title_year = re.search(r'(?<=\()(\d*)', title_year_raw).group(0)
    titles_cleaned.append({'Title': title_name, 'Year': title_year})
titles_data = pd.DataFrame(titles_cleaned) 
titles_data.to_csv('data/cleaned/jhu-titles.csv', index=False)
```

The resulting `jhu-titles.csv` can be shared with learners, and the code to scrape the information can be shared post-session for those that are interested.

## Retrieving the IMDB titles that correspond to the titles listed in `jhu-titles.csv`

This is more challenging than you might expect â€“ there are a number of duplicate titles for some of the JHU titles, so we need to do a little data cleaning, as well as some manual data exploration. 

The IMDB tabular data is large, so I use `duckdb` here to allow me to treat them as a SQL database. 

```{python}
con = duckdb.connect()
```

Query matching titles
```{python}
# Query for rows in IMDB title basics where the corresponding 
# title and year are present for the titles scraped from the JHU site
titles = con.execute(
    """
    SELECT *
    FROM read_csv_auto(
    "./data/title.basics.tsv", 
    header=True,
    nullstr="\\N") as tb
    JOIN titles_data as td ON tb.originalTitle = td.Title
    WHERE tb.startYear = td.Year
    """
).fetchdf()
titles.to_csv('data/cleaned/imdb-title-matches.csv', index=False)
```

## Selecting matching titles



Multiple joins with CTE's

```{python}
# Query for rows in IMDB title basics where the corresponding
# title and year are present for the titles scraped from the JHU site
df = con.execute(
    """
    WITH tb AS(
    SELECT *
    FROM read_csv_auto(
        "./data/title.basics.tsv", 
        header=True,
        nullstr="\\N"
    ) as titles_basics
    JOIN titles_data 
    ON titles_basics.originalTitle = titles_data.Title
    WHERE titles_basics.startYear = titles_data.Year),

    tr AS(
        SELECT 
        tb.*,
        tr.averageRating,
        tr.numVotes 
    FROM tb
    JOIN read_csv_auto(
        "./data/title.ratings.tsv",
        header=True,
        nullstr="\\N"
    ) as tr
    ON tb.tconst = tr.tconst
    )
    SELECT *
    FROM tr
    """
).fetchdf()

```

Data cleaning - find unique title and category

```{python}
df['startYear'] = pd.to_datetime(df['startYear'], format='%Y', errors='coerce')
df['endYear'] = pd.to_datetime(df['endYear'], format='%Y', errors='coerce')
# Locate first year of title, for all title and title type combinations
df.loc[df.groupby(['titleType', 'primaryTitle']).startYear.idxmin().dropna()]

#Questions:
#- For TV shows, do we return an average rating across all seasons/episodes?

#Get rotten tomato ratings:

rt_scores = pd.read_csv('./data/movie_info.csv')
title_rt_scores = rt_scores[rt_scores['title'].isin(titles)]
```

Questions/Comments

- Many titles missing in Rotten Tomatoes scores.
- How do we disambiguate House of Cards show from 1968 movie.
  
Scrape rotten tomatoes for individual titles:


```{python}
response = requests.get('https://www.rottentomatoes.com/tv/house-of-cards')
soup = BeautifulSoup(response.content, 'html.parser')
```


```{python}
critics_score = soup.find("rt-text", attrs={"slot": "criticsScore", "role":"button"}).get_text(strip=True)

audience_score = soup.find("rt-text", attrs={"slot": "audienceScore", "role":"button"}).get_text(strip=True)
```

Breadcrumbs:
- Turn scraper into function.
- Add TV or Movie to titles, as Rotten Tomatos URLs are either m or tv depending, i.e. https://www.rottentomatoes.com/tv/house_of_cards

```{python}

medium = ['m', 'm', 'tv', 'm', 'm', 'm', 'm', 'tv', 'm', 'tv', 'tv', 'm', 'm']
```

```{python}
# Call function
def url_constructor(title, medium):
    rt_title = re.sub(r"[^a-z0-9_]", "", title.lower().replace(" ", "_"))
    return f'https://www.rottentomatoes.com/{medium}/{rt_title}'
```

```{python}
rt_urls = []
for title, med in zip(titles, medium):
    url = url_constructor(title, med)
    rt_urls.append(url) 
```


```{python}
def get_rt_ratings(url):
    try: 
        response = requests.get(url)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        critics_score = soup.find("rt-text", attrs={"slot": "criticsScore", "role":"button"}).get_text(strip=True)
        audience_score = soup.find("rt-text", attrs={"slot": "audienceScore", "role":"button"}).get_text(strip=True)
        return {'critics': critics_score,'audience': audience_score}
    except requests.exceptions.HTTPError as err:
        return {'critics': None,'audience': None}
```


```{python}
audience_scores = []
critics_scores = []
for url in rt_urls:
    scores = get_rt_ratings(url)
    audience_scores.append(scores.get('audience'))
    critics_scores.append(scores.get('critics'))
```

Construct dataframe of media and ratings

```{python}
#| eval: false
data = {"media": titles,
"audience_score": audience_scores, 
"critics_scores": critics_scores}

df = pd.DataFrame(data)
```